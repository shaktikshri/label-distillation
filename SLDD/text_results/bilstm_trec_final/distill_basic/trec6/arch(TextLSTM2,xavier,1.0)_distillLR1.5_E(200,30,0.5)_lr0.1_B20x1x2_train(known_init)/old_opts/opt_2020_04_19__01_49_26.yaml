add_first: true
add_label_scaling: 0
arch: TextLSTM2
attack_class: 0
base_seed: 1
batch_size: 1024
checkpoint_interval: 10
dataset: trec6
dataset_labels:
- 0
- 1
- 2
- 3
- 4
- 5
dataset_normalization: !!python/tuple
- !!python/tuple
    - 0
- !!python/tuple
    - 0
dataset_root: ./data/text/trec
decay_epochs: 30
decay_factor: 0.5
device_id: 0
dist_metric: MSE
distill_epochs: 2
distill_lr: 1.5
distill_steps: 1
distilled_images_per_class_per_step: 20
distributed: false
dropout: false
epochs: 200
expr_name_format: null
freeze_data: false
image_dpi: 80
init: xavier
init_labels:
- 0
- 1
- 2
- 3
- 4
- 5
init_param: 1.0
input_size: 30
invert_dist: false
label_softmax: false
learnable_embedding: false
log_file: text_results/bilstm_trec_final/distill_basic/trec6/arch(TextLSTM2,xavier,1.0)_distillLR1.5_E(200,30,0.5)_lr0.1_B20x1x2_train(known_init)/output.log
log_interval: 100
log_level: INFO
lr: 0.1
maxlen: 30
mode: distill_basic
model_dir: ./models/
model_subdir_format: null
mult_label_scaling: 1
n_nets: 1
nc: 1
ninp: 100
no_log: false
ntoken: 8700
num_classes: 6
num_distill_classes: 6
num_workers: 8
phase: train
random_init_labels: ''
reproduction_test: false
results_dir: text_results/bilstm_trec_final
sample_n_nets: 1
source_dataset: null
start_time: '2020-04-19 01:49:26'
static_labels: 0
target_class: 1
test_batch_size: 1024
test_distill_epochs: null
test_distilled_images: loaded
test_distilled_lrs:
- loaded
test_n_nets: 1
test_n_runs: 1
test_name_format: null
test_nets_type: same_as_train
test_niter: 1
test_optimize_n_nets: 20
test_optimize_n_runs: null
textdata: true
train_nets_type: known_init
visualize: false
world_rank: 0
world_size: 1
